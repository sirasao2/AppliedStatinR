---
title: 'STAT 420: Homework 4'
author: "Fall 2016, Unger"
date: 'Due: Friday, September 30 by 11:50 PM CT'
output:
  html_document:
    theme: readable
    toc: yes
---

# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

Final submissions must be uploaded to our Compass 2g site on the Homework page. No email, hardcopy, or late submissions will be accepted.

- Your assignment must be submitted through the [submission link](https://compass2g.illinois.edu/webapps/assignment/uploadAssignment?content_id=_2282013_1&course_id=_28042_1&assign_group_id=&mode=cpview) on **Compass 2g.** You are required to attach one `.zip` file, named `hw02_yourNetID.zip`, which contains:
    - Your RMarkdown file which should be saved as `hw04_yourNetID.Rmd`. For example `hw04_dunger.Rmd`.
    - The result of knitting your RMarkdown file as `hw04_yourNetID.html`. For example `hw04_dunger.html`.
- Your resulting `.html` file will be considered a "report" which is the material that will determine the majority of your grade. Be sure to visibly include all `R` code and output that is relevant to answering the exercises. (You do not need to include irrelevant code you tried that resulted in error or did not answer the question correctly.)
- You are granted an unlimited number of submissions, but only the last submission *before* the deadline will be viewed and graded.
- If you use [this `.Rmd` file as a template](hw04.Rmd), be sure to remove the directions section. Consider removing `eval = FALSE` from any code chunks provided in the template, if you would like to run that code as part of your assignment.
- Your `.Rmd` file should be written such that, if it is placed in a folder with any data your are asked to import, it will knit properly without modification.
- Unless otherwise stated, you may use `R` for each of the exercises.
- Be sure to read each exercise carefully!
- Include your Name and NetID in the final document, not only in your filenames.

# Assignment

## Exercise 1 (Using `lm` and `anova`)

For this exercise we will use the data stored in [`nutrition.csv`](nutrition.csv). It contains the nutritional values per serving size for a large variety of foods as calculated by the USDA. It is a cleaned version totaling 5,138 observations and is current as of September 2015.

The variables in the dataset are:

- `ID` 
- `Desc` - Short description of food
- `Water` - in grams
- `Calories` 
- `Protein` - in grams
- `Fat` - in grams
- `Carbs` - Carbohydrates, in grams
- `Fiber` - in grams
- `Sugar` - in grams
- `Calcium` - in milligrams
- `Potassium` - in milligrams
- `Sodium` - in milligrams
- `VitaminC` - Vitamin C, in milligrams
- `Chol` - Cholesterol, in milligrams
- `Portion` - Description of standard serving size used in analysis


**(a)** Fit a model with `Calories` as the response and all other continuous variables as predictors. Leave out `ID`, `Desc`, and `Portion`. Store the results in a variable called `nut_full`. Use an $F$-test to test the significance of the regression. Report the following:

- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.01$.
- A conclusion in the context of the problem.
 
When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
#a. 
nutrition <- read.csv("C:/Users/Adminlocal/Desktop/nutrition.csv",TRUE) #knitted from a different computer

#In general, you should think of the syntax as response ~ predictor
nut_full = lm(formula = Calories ~ Water + Protein + Fat + Carbs + Fiber + Sugar + Calcium + Potassium + Sodium + VitaminC + Chol, data = nutrition)
summary(nut_full)


#Null Hypothesis: B1 = 0
#Alternative Hypothesis: B1 != 0

#Notice that the value reported in the row for F-statistic is indeed the F test statistic. Also the t-tests are equivalent to the F-test as if they were in SLR. Therefore the value of the test statistic is 7.571e+04 on 11 and 5126 DF

#p-value is < 2.2e-16 nd is very small (and smaller than alpha) therefore we reject the null hypothesis at any reasonable  α  level, for example at α=0.01. If the p value is less than alpha we reject the null hypothesis. If the null hypothesis is false then the alternative hypothesis is true.

#The regression is significant and atleast one of the included variables has a useful linear relationship with the Calories

```


**(b)** Now that you have made a decision about the validity of the full model based on the $F$-test, it's time to dig deeper. Look at the results of the single parameter $t$-tests by calling for the coefficient summary table of `nut_full`. Does what you observe in those results support or refute your response in part **(a)** in terms of practicality?

```{r}

summary(nut_full)$coef
#b. I may not use all the predicotrs used in the full model because some had pvalues greater than the alpha such as sugar and cholestrol.
```

Stated another way, after considering those single parameter $t$-tests for each predictor, would you want to change your mind about the usefulness or lack thereof of the full model? Explain your response.

**(c)** Fit a model with Calories as the response and `Carbs`, `Sodium`, `Fat`, and `Protein` as predictors. Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.01$.
- A conclusion in the context of the problem.

```{r}
#c.

nutrition <- read.csv("C:/Users/Adminlocal/Desktop/nutrition.csv")

nut_full = lm(formula = Calories ~ Carbs + Sodium + Fat + Protein, data = nutrition)
summary(nut_full)

#Null Hypothesis: B1 = 0
#Alternative Hypothesis: B1 != 0

#Notice that the value reported in the row for F-statistic is indeed the F test statistic. Also the t-tests are equivalent to the F-test as if they were in SLR. Therefore the value of the test statistic is 1.144e+05 on 4 and 5133 DF

#p-value is < 2.2e-16 nd is very small there for we reject the null hypothesis at any reasonable  α  level, for example at α=0.01. If the null hypothesis is false then the alternative hypothesis is true. The regression is significant and at least one of the included variables has a useful linear relationship with calories.

```

**(d)** For each of the predictors in part **(c)**, perform a $t$-test for the significance of its regression coefficient. Report the following for each:
 
- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.01$.

```{r}

carb_model = lm(Calories ~ Carbs, data = nutrition)
summary(carb_model)$coeff

#The t-value is 36.83286 and the p is 9.333486e-264 so therefore very small. If it is that small we reject the null hypothesis at any reasonable  α  level, for example at α=0.01. If the null hypothesis is false then the alternative hypothesis is true.

sodium_model = lm(Calories ~ Sodium, data = nutrition)
summary(sodium_model)$coeff

#The t-value is 2.824508 and the p is 0.004753582 so therefore very small. However, if the P-value is greater than α, you do not reject the null hypothesis. Alpha in this case is α=0.01 (which is greater) than 0.004753582, so we reject the null hypothesis. If the null hypothesis is false then the alternative hypothesis is true.

fat_model = lm(Calories ~ Fat, data = nutrition)
summary(fat_model)$coeff

##The t-value is 97.54211 and the p is 0. Alpha in this case is α=0.01 (which is greater) than 0, so we reject the null hypothesis. If the null hypothesis is false then the alternative hypothesis is true.

protien_model = lm(Calories ~ Protein, data = nutrition)
summary(protien_model)$coeff

##The t-value is 11.27085 and the p is 4.007413e-29. Alpha in this case is α=0.01 (which is greater) than 4.007413e-29, so we reject the null hypothesis. If the null hypothesis is false then the alternative hypothesis is true.




```

**(e)** Based on your results in part **(d)**, do you still prefer the model in part **(b)** or **(c)**, or is there instead a model with fewer predictors that you prefer? Briefly explain.

```{r}
#I liked c because the linear relationships are significant and if you use to many predictors you may over fit and have harder to interpret data.
```

## Exercise 2 (Using `lm` for Inference)

For this exercise we will again use the nutrition data. 

**(a)** Fit the following multiple linear regression model in `R`. Use `Calories` as the response and `Carbs`, `Fat`, and `Protein` as predictors.

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i.
\]

Here,

- $Y_i$ is `Calories`
- $x_{i1}$ is `Carbs`
- $x_{i2}$ is `Fat`
- $x_{i3}$ is `Protein`.

Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.01$.
- A conclusion in the context of the problem.

```{r}

null_nut_model = lm(Calories ~ 1, data = nutrition)
full_nut_model = lm(Calories ~ Carbs + Fat + Protein, data = nutrition)
anova(null_nut_model, full_nut_model)

#Null Hypothesis: B1 = 0
#Alternative Hypothesis: B1 != 0

#The value of the test statistic 152445

#p-value is < 2.2e-16 nd is very small (and smaller than alpha) therefore we reject the null hypothesis at any reasonable  α  level, for example at the given  α=0.01. If the p value is less than alpha we reject! If the null hypothesis is false then the alternative hypothesis is true. Regression is significant for atleast one of the included varibles and we can see a useful linear relationship.

```

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**(b)** Output only the estimated regression coefficients. Interpret all $\hat{\beta}_j$ coefficients in the context of the problem.

```{r}

coef(full_nut_model)

#  β^1  (carbs) 3.773605 is the average change in calories for a increase in carbs of 1 gram for certain protien and fat amounts

#  β^2 (fat) 8.804109 is the average change in calories for a increase in fat of 1 gram for certain protien and carb amounts

#  β^3 (protien) 3.967269 is the average change in calories for a increase in protien of 1 gram for certain fat and carb amounts
```

**(c)** Use your model to predict the amount of `Calories` in a Big Mac. According to [McDonald's publicized nutrition facts](http://nutrition.mcdonalds.com/getnutrition/nutritionfacts.pdf), the Big Mac contains 47g of Carbohydrates, 28g of Fat, and 25g of Protein. Do you feel confident in this prediction? Briefly explain.

```{r}

 pred =  3.768066 + (3.773605*47) + (8.804109*28) + (3.967269*25)
 pred

```

**(d)** Calculate the standard deviation, $s_y$, for the observed values in the Calories variable. Report the value of $s_e$ from your multiple regression model. Interpret both estimates in the context of this problem.

```{r}

summary(full_nut_model)$sigma

#se is 18.89119

```

**(e)** Report the value of $R^2$ for the model. Interpret its meaning in the context of the problem.

```{r}
summary(full_nut_model)$r.squared

#98.89% for the observed variation in calories can be explained by linear relationship with the 3 above predictors (carbs, protien, fat)



```
 
**(f)** Calculate a 90% confidence interval for $\beta_2$. Give an interpretation of the interval in the context of the problem.

```{r}

confint(full_nut_model, level = 0.90)

# β2 90% conf interval is 8.778930 and 8.829288


```
 
**(g)** Calculate a 95% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.
 
```{r}

confint(full_nut_model, level = 0.95)

# β0 95% conf interval is 2.802779 and 4.733353



```

**(h)** Use a 99% confidence interval to estimate the mean Calorie content of a small order of McDonald?s french fries that has 30g of Carbohydrates, 11g of Fat, and 2g of Protein. Interpret the interval in context.

```{r}

calorie_c = data.frame(Carbs = c(30), Fat = c(11), Protein= c(2))
predict(full_nut_model, newdata = calorie_c, interval = "prediction", level = 0.99)


```
 
**(i)** Use a 90% prediction interval to predict the Calorie content of new healthy menu item that has 11g of Carbohydrates, 1.5g of Fat, and 1g of Protein. Interpret the interval in context.

```{r}

calorie_c = data.frame(Carbs = c(11), Fat = c(1.5), Protein= c(1))
predict(full_nut_model, newdata = calorie_c, interval = "prediction", level = 0.90)

```

## Exercise 3 (Comparing Models)

For this exercise we will use the data stored in [`goalies_cleaned.csv`](goalies_cleaned.csv). It contains career data for 462 players in the National Hockey League who played goaltender at some point up to and including the 2014 - 2015 season. The variables in the dataset are:
 
- `W` - Wins
- `GA` - Goals Against
- `SA` - Shots Against
- `SV` - Saves
- `SV_PCT` - Save Percentage
- `GAA` - Goals Against Average
- `SO` - Shutouts
- `MIN` - Minutes
- `PIM` - Penalties in Minutes
 
**(a)** Fit a multiple linear regression model with Wins as the response and all other variables as the predictors.
 
Use an $F$-test to test the significance of the regression. Report the following:
 
- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.10$.
- A conclusion in the context of the problem.
 
When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
goalies_cleaned <- read.csv("C:/Users/Adminlocal/Desktop/goalies_cleaned.csv")

null_gc_model = lm(W ~ 1, data = goalies_cleaned)
full_gc_model = lm(W ~ GA + SA + SV + SV_PCT + GAA + SO + MIN + PIM, data = goalies_cleaned)
anova(null_gc_model, full_gc_model)


##Null Hypothesis: B1 = 0
#Alternative Hypothesis: B1 != 0

##The value of the test statistic 3938.3 with DF 8.

#p-value is < 2.2e-16 nd is very small (and smaller than alpha) therefore we reject the null hypothesis at any reasonable  α  level, for example at the given  α=0.01. If the p value is less than alpha we reject! If the null hypothesis is false then the alternative hypothesis is true.

```
**(b)** Calculate the RMSE of this full model. Report the residual standard error of this full model. What is the relationship of these two values?

Recall, we have defined RMSE as,

\[
RMSE = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}.
\]

```{r}
size = length(full_gc_model$residuals)
sum = sum(full_gc_model$residuals^2)
sum = sum/size
rmse = sqrt(sum)
rmse

summary(full_gc_model)
#rmse = 12.3962
#residual standard error = 12.52
#close in values 
```
 
**(c)** Fit a model with Wins as the response and with Goals Against, Goals Against Average, Saves, and Save Percentage as the predictors. Calculate the RMSE of this model.

```{r}

goalies_cleaned <- read.csv("C:/Users/Adminlocal/Desktop/goalies_cleaned.csv")

null_gc_model1 = lm(W ~ 1, data = goalies_cleaned)
full_gc_model1 = lm(W ~ GA + GAA + SV + SV_PCT, data = goalies_cleaned)

size = length(full_gc_model1$residuals)
sum = sum(full_gc_model1$residuals^2)
sum = sum/size
rmse = sqrt(sum)
rmse


```
 
**(d)** Fit a model with Wins as the response and with Goals Against Average and Save Percentage as the predictors. Calculate the RMSE of this model.

```{r}

goalies_cleaned <- read.csv("C:/Users/Adminlocal/Desktop/goalies_cleaned.csv")

null_gc_model2 = lm(W ~ 1, data = goalies_cleaned)
full_gc_model2 = lm(W ~ GAA + SV_PCT, data = goalies_cleaned)

size = length(full_gc_model2$residuals)
sum = sum(full_gc_model2$residuals^2)
sum = sum/size
rmse = sqrt(sum)
rmse

```
 
**(e)** Based on the previous three models, which model is most helpful for predicting wins? Briefly explain.

```{r}

#The first model is the most helpful for predicting wins because the rsme value is smallest there

```
 
**(f)** Conduct an ANOVA $F$-test comparing the models in parts **(c)** and **(d)**. Report the following:
 
- The null and alternative hypotheses.
- The value of the test statistic.
- The p-value of the test.
- A statistical decision at $\alpha = 0.10$.
- A conclusion in the context of the problem.
 
When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}

anova(full_gc_model1, full_gc_model2)

#Ftest: 3599.8
#Pvalue: < 2.2e-16
#Since p is smaller than alpha we reject null
#There is a significant linear relationship between the models


```

## Exercise 4 (Simulating Multiple Regression)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 2$
- $\beta_1 = 5$
- $\beta_2 = 0$
- $\beta_3 = 3$
- $\beta_4 = -1$
- $\sigma^2 = 16$

We will use samples of size `n = 25`.

We will verify the distribution of $\hat{\beta}_1$ as well as investigate some hypothesis tests.

**(a)** We will first generate the $X$ matrix and data frame which will be used throughout the exercise. Create the following 9 variables:

- `x0`: a vector of length `n` which contains all `1`.
- `x1`: a vector of length `n` which is randomly drawn from a uniform distribution between `0` and `10`.
- `x2`: a vector of length `n` which is randomly drawn from a uniform distribution between `0` and `10`.
- `x3`: a vector of length `n` which is randomly drawn from a uniform distribution between `0` and `10`.
- `x4`: a vector of length `n` which is randomly drawn from a uniform distribution between `0` and `10`.
- `X`: a matrix which contains `x0`, `x1`, `x2`, `x3`, `x4` as its columns.
- `C`: the $C$ matrix which is defined as $(X^\top X)^{-1}$.
- `y`: a vector of length `n` which contains all `0`.
- `ex_4_data`: a data frame which stores `y` and the **four** predictor variables. `y` is currently a placeholder which we will update during the simulation.

Report the diagonal of `C` as well as the 10th row of `ex_4_data`. For this exercise we will use the seed `930`.

```{r}
set.seed(930)
n = 25
beta_0 = 2
beta_1 = 5
beta_2 = 0
beta_3 = 3
beta_4 = -1

x0 = rep(1,25)
x1 = runif(25, min = 0, max = 10)
x2 = runif(25, min = 0, max = 10)
x3 = runif(25, min = 0, max = 10)
x4 = runif(25, min = 0, max = 10)
X = cbind(x0,x1,x2,x3,x4)
x_trans = t(X)
C = solve(x_trans %*% X)
y = rep(0,25)
ex_4_data = cbind(y,x1,x2,x3,x4)
sigma = 4
ex_4_data[10,]
diag(C)

```

**(b)** Create three vectors of length `1500` which will store results from the simulation in part **(c)**. Call them `beta_hat_1`, `beta_2_pval`, and `beta_3_pval`.
```{r}

beta_hat_1 = rep(0, 1500)
beta_2_pval = rep(0, 1500)
beta_3_pval = rep(0, 1500)



```

**(c)** Simulate 1500 samples of size `n = 25` from the model above. Each time update the `y` value of `ex_4_data`. Then use `lm()` to fit a multiple regression model. Each time store:

- The value of $\hat{\beta}_1$ in `beta_hat_1`.
- The p-value for the two-sided test of $\beta_2 = 0$ in `beta_2_pval`.
- The p-value for the two-sided test of $\beta_3 = 0$ in `beta_3_pval`.

```{r}

model = beta_0 + (beta_1*x1) + (beta_2*x2) + (beta_3*x3) + (beta_4*x4)
for(i in 1:1500){
  y = model+rnorm(25,0,sigma)
  beta_hat_1[i] = coef(lm(y~x1+x2+x3+x4))[2]
  beta_2_pval[i] = summary(lm(y~x1+x2+x3+x4))$coefficients[3,4]
  beta_3_pval[i] = summary(lm(y~x1+x2+x3+x4))$coefficients[4,4]
} 




```

**(d)** Based on the known values of $X$, what is the true distribution of $\hat{\beta}_1$?

```{r}

sxx = sum((x1-mean(x1))^2)
result = sigma/sqrt(sxx)
result
# E[beta_1_hat] = 5
# SE[beta_1_hat] = 0.3091667
# var = 0.3091667^2
# beta_1_hat ~ N(5, .09558404838)



```

**(e)** Calculate the mean and variance of `beta_hat_1`. Are they close to what we should expect? Plot a histogram of `beta_hat_1`. Add a curve for the true distribution of $\hat{\beta}_1$. Does the curve seem to match the histogram?

```{r}

mean(beta_hat_1)
var(beta_hat_1)
# mean = 4.986553
# variance = 0.1095403
hist(beta_hat_1, prob = TRUE, breaks = 20, xlab = expression(hat(beta)[1]), main = "Histo of beta_hat_1", border = "pink")
curve(dnorm(x, mean = mean(beta_hat_1), sd = sqrt(var(beta_hat_1))), 
      col = "red", add = TRUE, lwd = 3)


```

**(f)** What proportion of the p-values stored in `beta_2_pval` are less than 0.05? Is this what you would expect?

```{r}

size = length(beta_2_pval)
count = 0
for(i in 1:size){
  if(beta_2_pval[i] < 0.05){
    count = count + 1
  }
}
prop = count/size
prop

```

**(g)** What proportion of the p-values stored in `beta_3_pval` are less than 0.05? Is this what you would expect?

```{r}

size = length(beta_3_pval)
count2 = 0
for(i in 1:size){
  if(beta_3_pval[i] < 0.05){
    count2 = count2 +1
  }
}
prop2 = count2/size
prop2
# 100% of the p-values are less than 0.05

```

