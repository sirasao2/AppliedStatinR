---
title: 'STAT 420: Homework 9'
author: "Fall 2016, Unger"
date: 'Due: Thursday, December 1 by 11:50 PM CT'
output:
  html_document:
    theme: readable
    toc: yes
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```

# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

Final submissions must be uploaded to our Compass 2g site on the Homework page. No email, hardcopy, or late submissions will be accepted.

- Your assignment must be submitted through the [submission link](https://compass2g.illinois.edu/webapps/assignment/uploadAssignment?content_id=_2354785_1&course_id=_28042_1&assign_group_id=&mode=cpview) on **Compass 2g.** You are required to attach one `.zip` file, named `hw09_yourNetID.zip`, which contains:
    - Your RMarkdown file which should be saved as `hw09_yourNetID.Rmd`. For example `hw09_dunger.Rmd`.
    - The result of knitting your RMarkdown file as `hw09_yourNetID.html`. For example `hw09_dunger.html`.
- Your resulting `.html` file will be considered a "report" which is the material that will determine the majority of your grade. Be sure to visibly include all `R` code and output that is relevant to answering the exercises. (You do not need to include irrelevant code you tried that resulted in error or did not answer the question correctly.)
- You are granted an unlimited number of submissions, but only the last submission *before* the deadline will be viewed and graded.
- If you use [this `.Rmd` file as a template](hw09.Rmd), be sure to remove the directions section. Consider removing `eval = FALSE` from any code chunks provided in the template, if you would like to run that code as part of your assignment.
- Your `.Rmd` file should be written such that, if it is placed in a folder with any data your are asked to import, it will knit properly without modification.
- Unless otherwise stated, you may use `R` for each of the exercises.
- Be sure to read each exercise carefully!
- Include your Name and NetID in the final document, not only in your filenames.

# Assignment

## Exercise 1 (`longley` Macroeconomic data)

The data set `longley` from the `faraway` package contains macroeconomic data for predicting employment.

```{r}
library(faraway)
```

```{r, eval = FALSE}
View(longley)
?longley
```

**(a)** Find the correlation between each of the variables in the dataset.

```{r}
cor(longley)
```

**(b)** Fit a model with `Employed` as the response and the remaining variables as predictors. Calculate the variance inflation factor for each of the predictors. What is the largest VIF? Do any of the VIFs suggest multicollinearity?

```{r}
library(faraway)
long_model = lm(Employed ~ ., data = longley)
vif(long_model)
max(vif(long_model))

#Largest is GNP: 1788.513. 
#Any VIF greater than 5 will suggest multicollinearity. From that we can conclude that all VIF's, besides for Armed Forces, suggest multicollinearrity.
```

**(c)** What proportion of observed variation in `Population` is explained by a linear relationship with the other predictors?

```{r}

popu_model = lm(Population ~ . - Employed, data=longley)
summary(popu_model)$r.squared

```

**(d)** Calculate the partial correlation coefficient for `Population` and `Employed` **with the effects of the other predictors removed**.

```{r}
long_model = lm(Employed ~ . , data = longley)
popu_model = lm(Population ~ . - Employed, data=longley)
cor(resid(popu_model), resid(long_model))
```

**(e)** Fit a new model with `Employed` as the response and the predictors from the model in **(b)** which were significant. (Use $\alpha = 0.05$.) Calculate the variance inflation factor for each of the predictors. What is the largest VIF? Do any of the VIFs suggest multicollinearity?

```{r}
long_model = lm(Employed ~ . , data = longley)
summary(long_model)

new_model = lm(Employed~Year+Armed.Forces+Unemployed, data = longley)
vif(new_model)
max(vif(new_model))

#Largest VIP is Year: 3.89. None others are larger than 5, so do not suggest multicollinearity.
```

**(f)** Use an $F$-test to compare the models in parts **(b)** and **(e)**. Report the following:

- The null hypothesis.
- The test statistic.
- The distribution of the test statistic under the null hypothesis.
- The p-value.
- A decision.
- Which model you prefer. **(b)** or **(e)**

```{r}
anova(long_model, new_model)

#Null Hypothesis: B_0 = 0
#The test statistic is 1.7465. The F-distribution is ratio of 9 and 12 degrees of freedom under the null hypothesis, and the pvalue is .227.
#We can see that the pvalue is greater than alpha of 0.05, so we reject the null hypothesis the first model. There for model a (the bigger model) is much more useful to use.
```

**(g)** Check the assumptions of the model chosen in part **(f)**. Do any assumptions appear to be violated?

```{r}
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  plot(fitted(model), resid(model), 
       col = pointcol, pch = 20, cex = 1.5,
       xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}

plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
  qqline(resid(model), col = linecol, lwd = 2)
}
```

```{r}
shapiro.test(resid(long_model))

#Normality assumption not violated because the p-value is not very low.

qqnorm(resid(long_model), main = "Normal Q-Q Plot, fit1", col = "dodgerblue")
qqline(resid(long_model), col = "pink", lwd = 2)

#the lines fit very well as well as we can see from the plot.
```
## Exercise 2 (`odor` Chemical Data)

Use the `odor` data from the `faraway` package for this question.

**(a)** Fit a complete second order model with `odor` as the response and the three other variables as predictors. That is use each first order term, their two-way interactions, and the quadratic term for each of the predictors. Perform the significance of the regression test. Use a level of $\alpha = 0.10$. Report the following:

- The test statistic.
- The distribution of the test statistic under the null hypothesis.
- The p-value.
- A decision.

```{r}
o_model = lm(odor ~ . ^ 2 + I(temp^2) + I(gas^2) + I(pack^2), data = odor)
summary(o_model)

#The test Statistic is 4.15 and the F-Distribution is ratio of 9 and 5 degrees of freedom. We can see the p-value is 0.0657
#Therefore we reject the null hypothesis at alpha = 0.10 because the p-value is smaller.
```

**(b)** Fit a model with the same response, but now excluding any interaction terms. So, include all linear and quadratic terms. Compare this model to the model in **(a)** using an appropriate test. Use a level of $\alpha = 0.10$. Report the following:

- The test statistic.
- The distribution of the test statistic under the null hypothesis.
- The p-value.
- A decision.

```{r}
o_model1 = lm(odor ~ . + I(gas^2) + I(temp^2) + I(pack^2), data = odor)

anova(o_model1, o_model)

#The test statistic is .1936 and the F distribution is ratio of 8 and 5 degrees of freedom. The pvalue is .8965 or .9 so we fail to reject the null at the alpha because the p-value  is greater. The o_model1 is the better of the two.
```

**(c)** Report the proportion of the observed variation of `odor` explained by the two previous models.

```{r}
summary(o_model)$r.squared
summary(o_model1)$r.squared
```

**(d)** Use adjusted $R^2$ to pick from the two models. Report both values. Does this decision match the decision made in part **(b)**?

```{r}
summary(o_model)$adj.r.squared
summary(o_model1)$adj.r.squared

#This matches our previous conclusion of o_model1. This is apparent because the R^2 is larger.
```

## Exercise 3 (`teengamb` Gambling Data)

The `teengamb` dataset from the `faraway` package contains data related to teenage gambling in Britain.

**(a)** Fit an additive model with `gamble` as the response and the other variables as predictors. Use backward AIC variable selection to determine a good model. When writing your final report, you may wish to use `trace = 0` inside of `step()` to minimize unneeded output. (This advice is also useful for future questions which use `step()`.)

```{r}
t_model = lm(gamble ~ ., data = teengamb)

t_model_aic = step(t_model, direction = "backward", trace = 0)
t_model_aic
```

**(b)** Use backward BIC variable selection to determine a good model.

```{r}
t_model_bic = step(t_model, direction = "backward", k = log(length(resid(t_model))))
t_model_bic
```

**(c)** Use a statistical test to compare these two models. Use a level of $\alpha = 0.10$. Report the following:

- The test statistic.
- The distribution of the test statistic under the null hypothesis.
- The p-value.
- A decision.

```{r}
t_model_bic = step(t_model, direction = "backward", k = log(length(resid(t_model))))
t_model_aic = step(t_model, direction = "backward", trace = 0)
anova(t_model_aic, t_model_bic)

#The test stat is 2.26. The F-distribution is ratio between 43 and 44 degrees of freedom and we have a pvalue of 0.14. We do not reject the null hypothesis so the aic model is much better.
```

**(d)** Fit a model with `gamble` as the response and the other variables as predictors with *all* possible interactions, up to and including a four-way interaction. Use backward AIC variable selection to determine a good model. 

```{r}
t_model1 = lm(gamble ~ sex + status + income + verbal + sex*verbal + sex*income + sex*status + status*verbal + status*income + income*verbal + sex*status*verbal + sex*status*income + sex*income*verbal + status*income*verbal + sex*status*income*verbal, data = teengamb)

t_model1_aic = step(t_model1, direction = "backward", trace = 0)
t_model1_aic
```

**(e)** Compare the values of Adjusted $R^2$ for the each of the five previous models. Which model is the "best" model out of the five? Justify your answer.

```{r}
summary(t_model)$adj.r.squared 
summary(t_model1)$adj.r.squared 
summary(t_model_aic)$adj.r.squared 
summary(t_model_bic)$adj.r.squared 
summary(t_model1_aic)$adj.r.squared 

#We pick the model wih the largest R^2 value. Therefore t_model1_aic is the best.

```
